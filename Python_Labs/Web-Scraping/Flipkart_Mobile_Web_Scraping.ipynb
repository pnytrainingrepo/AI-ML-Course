{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement: Web Scraping Product Information from Flipkart\n",
    "\n",
    "**Background:**\n",
    "\n",
    "Flipkart is an e-commerce platform where users can search for and purchase various products. It contains a vast catalog of products with details such as product names, prices, sellers, and additional specifications. To gather data for analysis or other purposes, it can be valuable to extract specific product information from Flipkart's website programmatically.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "The objective of this project is to create a Python script that performs web scraping on Flipkart's website to extract essential information about Samsung mobile phone and store it for further analysis or use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract title\n",
    "def get_title(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract and clean the product title\n",
    "        title_value = soup.find(\"span\",class_=\"B_NuCI\").text.replace(\"\\xa0\",\"\")\n",
    "    except:\n",
    "        # If the title is not found, set it as an empty string\n",
    "        title_value = \"\"\n",
    "        \n",
    "    return title_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract price\n",
    "def get_price(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract the product price\n",
    "        price_value = soup.find(\"div\",class_=\"_30jeq3 _16Jk6d\").text\n",
    "    except:\n",
    "        # If the price is not found, set it as an empty string\n",
    "        price_value = \"\"\n",
    "    \n",
    "    return price_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract rating\n",
    "def get_rating(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract the product rating\n",
    "        rating_value = soup.find(\"div\",class_=\"_3LWZlK\").text\n",
    "    except:\n",
    "        # If the rating is not found, set it as an empty string\n",
    "        rating_value = \"\"\n",
    "    \n",
    "    return rating_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract number of reviews\n",
    "def get_num_review(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract the number of reviews\n",
    "        reviews_value = soup.find(\"span\",class_=\"_2_R_DZ\").find_all(\"span\")[3].text.replace(\"\\xa0\",\"\")\n",
    "    except:\n",
    "        # If the number of reviews is not found, set it as an empty string\n",
    "        reviews_value = \"\"\n",
    "    \n",
    "    return reviews_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract product color\n",
    "def get_color(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract the product color\n",
    "        color_value = soup.find_all(\"tr\",class_=\"_1s_Smc row\")[3].find(\"li\",class_=\"_21lJbe\").text\n",
    "    except:\n",
    "        # If the color is not found, set it as an empty string\n",
    "        color_value = \"\"\n",
    "    \n",
    "    return color_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract product display size\n",
    "def get_display_size(soup):\n",
    "    \n",
    "    try:\n",
    "        # Extract the product display size\n",
    "        display_value = soup.find_all(\"tr\",class_=\"_1s_Smc row\")[9].find(\"li\",class_=\"_21lJbe\").text\n",
    "    except:\n",
    "        # If the display size is not found, set it as an empty string\n",
    "        display_value = \"\"\n",
    "    \n",
    "    return display_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the user-agent headers for HTTP requests\n",
    "HEADERS = {\"User-Agent\":'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for Flipkart's Samsung product search\n",
    "URL = \"https://www.flipkart.com/search?q=samsung&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send an HTTP GET request to the search page\n",
    "response = requests.get(URL,headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the HTTP response object\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html><html lang=en><meta charset=UTF-8><meta content=\"width=device-width,initial-scale=1\"name=viewport><title>Flipkart reCAPTCHA</title><link href=https://static-assets-web.flixcart.com/batman-returns/batman-returns/s/recaptcha.css rel=stylesheet><script src=\"https://www.google.com/recaptcha/api.js?render=6Lc49B0pAAAAAIVgOhfwW8i7t7SRO0KSnlSVZRAq\"></script><script src=https://static-assets-web.flixcart.com/batman-returns/batman-returns/s/recaptcha.js async defer></script><div class=container><img alt=\"Flipkart Logo\"class=logo src=\"https://rukminim1.flixcart.com/www/60/60/promos/14/06/2024/88011666-ce1d-40f0-a8eb-1bac7d164885.png?q=60\"><h1 class=header>Are you a human?</h1><p class=subText>Confirming...<div class=loaderContainer><div class=loader></div></div></div>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all product links on the search results page\n",
    "links = soup.find_all(\"a\",class_=\"s1Q9rs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store product URLs\n",
    "links_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product URLs and store them in the list\n",
    "for link in links:\n",
    "    links_list.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store scraped data\n",
    "d = {\"title\":[],\"price\":[],\"rating\":[],\"num_review\":[],\"color\":[],\"display\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through product URLs and scrape data\n",
    "for link in links_list:\n",
    "    \n",
    "    # Create the full URL for the product page\n",
    "    new_webpage_URL = \"https://www.flipkart.com\" + link\n",
    "    \n",
    "    # Send an HTTP GET request to the product page and parse the HTML content\n",
    "    new_response = requests.get(new_webpage_URL,headers=HEADERS)\n",
    "    new_soup = BeautifulSoup(new_response.content,\"html.parser\")\n",
    "    \n",
    "    # Call the defined functions to extract and append data to the dictionary\n",
    "    d[\"title\"].append(get_title(new_soup))\n",
    "    d[\"price\"].append(get_price(new_soup))\n",
    "    d[\"rating\"].append(get_rating(new_soup))\n",
    "    d[\"num_review\"].append(get_num_review(new_soup))\n",
    "    d[\"color\"].append(get_color(new_soup))\n",
    "    d[\"display\"].append(get_display_size(new_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azam\\AppData\\Local\\Temp\\ipykernel_8692\\791986248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"title\"].replace(\"\",np.nan,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# Replace empty strings in the \"title\" column with NaN and drop rows with NaN values in the \"title\" column\n",
    "df[\"title\"].replace(\"\",np.nan,inplace=True)\n",
    "df = df.dropna(subset=[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_review</th>\n",
       "      <th>color</th>\n",
       "      <th>display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, price, rating, num_review, color, display]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"Flipkart_samsung_phone_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
